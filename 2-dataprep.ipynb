{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e669bf17",
   "metadata": {},
   "source": [
    "# 2. Data Preparation\n",
    "\n",
    "a. Handle missing or erroneous data. <br>\n",
    "b. Encode categorical variables appropriately. <br>\n",
    "c. Normalize or standardize features as required. <br>\n",
    "d. Split the data into training and testing sets to evaluate model performance. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993831ca",
   "metadata": {},
   "source": [
    "#### Importing the relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2e813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3f900c",
   "metadata": {},
   "source": [
    "#### 2a. Handle missing or erroneous data. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719e7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (20501, 15)\n",
      "Full rows shape: (9531, 15)\n"
     ]
    }
   ],
   "source": [
    "csv_path = Path(\"dataset.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Total number of rows in the dataset with all the fields filled - No missing values\n",
    "df_full = df.dropna()\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"Full rows shape:\", df_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "280bccde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/03/2022 10:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15/03/2022 10:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15/03/2022 10:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/03/2022 10:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15/03/2022 10:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20496</th>\n",
       "      <td>17/06/2024 11:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20497</th>\n",
       "      <td>17/06/2024 12:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20498</th>\n",
       "      <td>17/06/2024 12:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20499</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20500</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20501 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time_step\n",
       "0      15/03/2022 10:24\n",
       "1      15/03/2022 10:24\n",
       "2      15/03/2022 10:24\n",
       "3      15/03/2022 10:24\n",
       "4      15/03/2022 10:24\n",
       "...                 ...\n",
       "20496  17/06/2024 11:54\n",
       "20497  17/06/2024 12:04\n",
       "20498  17/06/2024 12:14\n",
       "20499                  \n",
       "20500                  \n",
       "\n",
       "[20501 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of columns of the dataset having No row as missing\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "277e8b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2953)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sender_Id.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a8c568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time_step              0\n",
       "Transaction_Id         2\n",
       "Sender_Id           2953\n",
       "Sender_Account      2953\n",
       "Sender_Country      2953\n",
       "Sender_Gender       3886\n",
       "Sender_Sector       2953\n",
       "Sender_lob          2953\n",
       "Bene_Id             2969\n",
       "Bene_Account        2969\n",
       "Bene_Country        2969\n",
       "Bene_Gender         3887\n",
       "USD_amount             2\n",
       "Label                  2\n",
       "Transaction_Type       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86999181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Split target / features\n",
    "target_col = \"Label\"\n",
    "x = df.drop(columns=[target_col])\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b18b0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning target:\n",
      "X shape: (20499, 14)\n",
      "y shape: (20499,)\n",
      "Target distribution:\n",
      "Label\n",
      "0.0    20107\n",
      "1.0      392\n",
      "Name: count, dtype: int64\n",
      "Numerical columns: ['Sender_Sector', 'USD_amount']\n",
      "Categorical columns: ['Time_step', 'Transaction_Id', 'Sender_Id', 'Sender_Account', 'Sender_Country', 'Sender_Gender', 'Sender_lob', 'Bene_Id', 'Bene_Account', 'Bene_Country', 'Bene_Gender', 'Transaction_Type']\n",
      "Training set: (16399, 14)\n",
      "Test set: (4100, 14)\n"
     ]
    }
   ],
   "source": [
    "# 0) Handle missing values in target first\n",
    "target_col = \"Label\"\n",
    "x = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Remove rows with missing target values\n",
    "mask = ~y.isna()\n",
    "x_clean = x[mask]\n",
    "y_clean = y[mask]\n",
    "\n",
    "print(f\"After cleaning target:\")\n",
    "print(f\"X shape: {x_clean.shape}\")\n",
    "print(f\"y shape: {y_clean.shape}\")\n",
    "print(f\"Target distribution:\\n{y_clean.value_counts()}\")\n",
    "\n",
    "# 1) Defining column selectors for categorising into numerical and categorical\n",
    "num_col = selector(dtype_include=[\"int64\", \"float64\"])(x_clean)  # Apply selector to data\n",
    "cat_col = selector(dtype_include=[\"object\",\"category\",'bool'])(x_clean)  # Apply selector to data\n",
    "\n",
    "print(f\"Numerical columns: {num_col}\")\n",
    "print(f\"Categorical columns: {cat_col}\")\n",
    "\n",
    "# 2) Preprocessing the dataset : imputing -> encoding/scaling\n",
    "num_pipe = Pipeline(steps= [\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline(steps= [\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),  # Fixed strategy\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_col),\n",
    "        (\"cat\", cat_pipe, cat_col)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# 3) Splitting the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_clean, y_clean, test_size=0.2, random_state=42, stratify=y_clean\n",
    ")\n",
    "\n",
    "print(f\"Training set: {x_train.shape}\")\n",
    "print(f\"Test set: {x_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
