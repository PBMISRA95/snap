{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34cf0f6a",
   "metadata": {},
   "source": [
    "# 5. Model Selection and 6. Model Training \n",
    "\n",
    "### 5. Model Selection\n",
    "\n",
    "a. Test multiple algorithms, such as Decision Trees, Random Forest, \n",
    "Gradient Boosting, or XGBoost. <br>\n",
    "b. Use cross-validation to assess each modelâ€™s robustness and avoid overfitting.<br> \n",
    "c. Choose a model that provides the best balance of performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2936557a-6e33-4b73-92bf-62451edbd7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataprep_module...\n",
      "Data loaded: 20499 samples, 14 features\n",
      "Fraud rate: 1.91%\n",
      "Using 5-fold stratified cross-validation\n",
      "Preprocessing data once and storing in memory...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data shape: (20499, 57933)\n",
      "Memory usage: ~8.85 GB\n",
      "Data types: <class 'numpy.ndarray'>\n",
      "Sample values: [0.51637396 0.31874451 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataprep_module import load_and_prepare_data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data from preprocessing module\n",
    "print(\"Loading data from dataprep_module...\")\n",
    "x, y, preprocess = load_and_prepare_data()\n",
    "print(f\"Data loaded: {x.shape[0]} samples, {x.shape[1]} features\")\n",
    "print(f\"Fraud rate: {y.mean()*100:.2f}%\")\n",
    "\n",
    "# Set up cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(f\"Using {cv.n_splits}-fold stratified cross-validation\")\n",
    "\n",
    "# ADD THIS PART - Preprocess data once and store in memory\n",
    "print(\"Preprocessing data once and storing in memory...\")\n",
    "x_processed = preprocess.fit_transform(x)\n",
    "print(f\"Processed data shape: {x_processed.shape}\")\n",
    "print(f\"Memory usage: ~{x_processed.nbytes / 1024**3:.2f} GB\")\n",
    "print(f\"Data types: {type(x_processed)}\")\n",
    "print(f\"Sample values: {x_processed[0][:5]}\")  # Show first 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49caf046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MODEL 2: DECISION TREE\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC  : 0.640 (+/- 0.031)\n",
      "ACCURACY : 0.513 (+/- 0.128)\n",
      "PRECISION: 0.028 (+/- 0.002)\n",
      "RECALL   : 0.721 (+/- 0.182)\n",
      "F1       : 0.054 (+/- 0.003)\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Decision Tree\n",
    "# TO TAKE\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"MODEL 2: DECISION TREE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "dt_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"classifier\", DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2\n",
    "    ))\n",
    "])\n",
    "\n",
    "scorers_dt = {\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\"\n",
    "}\n",
    "\n",
    "# Cross-validation scores\n",
    "dt_auc_scores = cross_validate(\n",
    "    dt_model, \n",
    "    x, y, \n",
    "    cv=cv, \n",
    "    scoring=scorers_dt)\n",
    "\n",
    "\n",
    "for m in scorers_dt:\n",
    "    s = dt_auc_scores[f\"test_{m}\"]\n",
    "    print(f\"{m.upper():<9}: {s.mean():.3f} (+/- {s.std()*2:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3854a724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MODEL 3: HIST-GRADIENT BOOSTING (EARLY STOP)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC  : 0.673 (+/- 0.047)\n",
      "ACCURACY : 0.981 (+/- 0.000)\n",
      "PRECISION: 0.750 (+/- 0.775)\n",
      "RECALL   : 0.018 (+/- 0.026)\n",
      "F1       : 0.035 (+/- 0.050)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"MODEL 3: HIST-GRADIENT BOOSTING (EARLY STOP)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "hgb_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"classifier\", HistGradientBoostingClassifier(\n",
    "        random_state=42,\n",
    "        max_iter=300,            # like n_estimators\n",
    "        learning_rate=0.08,\n",
    "        max_leaf_nodes=31,\n",
    "        early_stopping=True,     # <- built-in early stopping\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=20\n",
    "    ))\n",
    "])\n",
    "\n",
    "scorers_hgb = {\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\"\n",
    "}\n",
    "\n",
    "hgb_cv = cross_validate(\n",
    "    hgb_model, \n",
    "    x, y, \n",
    "    cv=cv, \n",
    "    scoring=scorers_hgb, \n",
    "    n_jobs=-1)\n",
    "\n",
    "for m in scorers_hgb:\n",
    "    s = hgb_cv[f\"test_{m}\"]\n",
    "    print(f\"{m.upper():<9}: {s.mean():.3f} (+/- {s.std()*2:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33fcf6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MODEL 4: EXTRA TREES (PARALLEL & FAST)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC  : 0.699 (+/- 0.074)\n",
      "ACCURACY : 0.940 (+/- 0.015)\n",
      "PRECISION: 0.066 (+/- 0.039)\n",
      "RECALL   : 0.155 (+/- 0.053)\n",
      "F1       : 0.092 (+/- 0.046)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"MODEL 4: EXTRA TREES (PARALLEL & FAST)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "et_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"classifier\", ExtraTreesClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=400,\n",
    "        max_depth=None,          # let trees grow; try 20 if overfitting\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1,               # parallel\n",
    "        bootstrap=False,         # typical for ExtraTrees\n",
    "        max_features=\"sqrt\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "scores_et = {\n",
    "    \"roc_auc\": \"roc_auc\",\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\"\n",
    "}\n",
    "\n",
    "et_cv = cross_validate(\n",
    "    et_model, \n",
    "    x, y, \n",
    "    cv=cv, \n",
    "    scoring=scores_et,\n",
    "    n_jobs=-1)\n",
    "    \n",
    "for m in scores_et:\n",
    "    s = et_cv[f\"test_{m}\"]\n",
    "    print(f\"{m.upper():<9}: {s.mean():.3f} (+/- {s.std()*2:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b85cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"MODEL 5: XGBOOST (FAST)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "xgb_model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"classifier\", XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",   # fast CPU histogram algorithm\n",
    "        n_jobs=-1,\n",
    "        reg_lambda=1.0,\n",
    "        eval_metric=\"logloss\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "scores_xgb = {\n",
    "    \"roc_auc\":\"roc_auc\",\n",
    "    \"accuracy\":\"accuracy\",\n",
    "    \"precision\":\"precision\",\n",
    "    \"recall\":\"recall\",\n",
    "    \"f1\":\"f1\"\n",
    "    }\n",
    "\n",
    "xgb_cv = cross_validate(\n",
    "    xgb_model, x, y, \n",
    "    cv=cv, \n",
    "    scoring=scores_xgb, \n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd3441a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC  : 0.635 (+/- 0.032)\n",
      "ACCURACY : 0.981 (+/- 0.000)\n",
      "PRECISION: 0.783 (+/- 0.389)\n",
      "RECALL   : 0.023 (+/- 0.019)\n",
      "F1       : 0.044 (+/- 0.036)\n"
     ]
    }
   ],
   "source": [
    "for m in scores_xgb:\n",
    "    s = xgb_cv[f\"test_{m}\"] \n",
    "    print(f\"{m.upper():<9}: {s.mean():.3f} (+/- {s.std()*2:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2d99e",
   "metadata": {},
   "source": [
    "# 6. Model Training & Evaluation:\n",
    "\n",
    "a. Train the selected model on the training set. <br>\n",
    "b. Evaluate model performance using metrics suitable for imbalanced data (e.g., precision-recall curve, ROC-AUC score). <br>\n",
    "c. Document the performance metrics, including confusion matrix, precision, recall, and F1-score. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad7fa111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EXTRA TREES - TRAIN/TEST SPLIT (80/20)\n",
      "==================================================\n",
      "Training set: 16399 samples\n",
      "Test set: 4100 samples\n",
      "Training fraud rate: 1.91%\n",
      "Test fraud rate: 1.90%\n",
      "\n",
      "Training Extra Trees model on training data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed!\n",
      "\n",
      "ROC-AUC Score: 0.694\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97      4022\n",
      "         1.0       0.08      0.17      0.11        78\n",
      "\n",
      "    accuracy                           0.95      4100\n",
      "   macro avg       0.53      0.57      0.54      4100\n",
      "weighted avg       0.97      0.95      0.96      4100\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3881  141]\n",
      " [  65   13]]\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Model - Train/Test Split (80/20) using existing model\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"EXTRA TREES - TRAIN/TEST SPLIT (80/20)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Split data into train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Training fraud rate: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Test fraud rate: {y_test.mean()*100:.2f}%\")\n",
    "\n",
    "# Train the Extra Trees model on training data\n",
    "print(\"\\nTraining Extra Trees model on training data...\")\n",
    "et_model.fit(X_train, y_train)\n",
    "print(\"Model training completed!\")\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = et_model.predict(X_test)\n",
    "y_pred_proba = et_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Create final_scores_best_model dictionary with all metrics\n",
    "final_scores_best_model = {\n",
    "    \"roc_auc\": roc_auc_score(y_test, y_pred_proba),\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "    \"precision\": precision_score(y_test, y_pred),\n",
    "    \"recall\": recall_score(y_test, y_pred),\n",
    "    \"f1\": f1_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "print(f\"\\nROC-AUC Score: {final_scores_best_model['roc_auc']:.3f}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
